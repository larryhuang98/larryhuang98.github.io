---
title: "MPI--Grouping messages"
date: 2023-06-02
categories: [MPI, coding]
---
In parallel programming, sending a message is an expensive operation. One good approach of reducing time for message transfer is to group several message together. MPI provides three machanisms for grouping individual data items into a single message:
1. `count` parameter to various communication rountines
2. derived datatypes
3. `MPI_Pack/MPI_Unpack`

## Using `count` parameter

In order to group data items having the same basic type into a single message, and the grouped data items must be stored in contiguous memory locations. If one is sending multiple data which has same datatype, it is wise to combine them in an array and then transfer message.

## Derived Types


However, it can be impratical when we want to transfer multi-datatype data items as the memory location can hardly be contiguous. A good idea is to struct a new datatype to save the data.

Disappointingly, using `struct` from C directly will not work for MPI data transfer as the our defined type can not be inputed as a variable for function argument. A good approach is that one can create a corresponding MPI_Datatype variable which is a pointer to the new MPI_datatype.

### MPI_Type_struct
A general MPI_Datatype or derived datatype can be constructed using `MPI_Type_struct` as a sequence of pairs which contains the basic MPI_Datatype and displacement in address. The new datattype is shown below:

$$
\{(t_0,d_0),(t_1,d_1),...,(t_{n-1},d_{n-1})\}
$$

One example is provided below
```C
void Build_derived_types(float* a_ptr, float* b_ptr, int* n_ptr, MPI_Datatype* mesg_mpi_t_ptr){
	int block_lengths[3];
	MPI_Aint displacements[3];//MPI_Aint("address int") is an MPI defined C type
	MPI_Datatype typelist[3];

	MPI_Aint start_address;
	MPI_Aint address;

	block_lengths[0] = block_lengths[1] = block_lengths[2] = 1;

	typelist[0] = MPI_FLOAT;
	typelist[1] = MPI_FLOAT;
	typelist[2] = MPI_INT;

	displacements[0] = 0;
	MPI_Address(a_ptr, &start_address);
	MPI_Address(b_ptr, &address);
	displacements[1] = address - start_address;
	MPI_Address(n_ptr, &address);
	displacements[2] = address - start_address;

	MPI_Type_struct(3,block_lengths, displacements, typelist, mesg_mpi_t_ptr);
	MPI_Type_commit(mesg_mpi_t_ptr);
}
void Get_data(){
	MPI_Datatype mesg_mpi_t;
	float* a_ptr, b_ptr;
	int* n_ptr;
	Build_derived_types(a_ptr, b_ptr, n_ptr, &mesg_mpi_t);
	MPI_Bcast(a_ptr, 1, mesg_mpi_t, 0, MPI_COMM_WORLD);
}
```
The details of `MPI_Type_struct` function is shown below:
```c
int MPI_Type_struct(int count,
                   const int* array_of_blocklengths,
                   const MPI_Aint* array_of_displacements,
                   const MPI_Datatype* array_of_types,
                   MPI_Datatype *newtype)
```
And for `MPI_Address`, it returns the address of location
```C
MPI_Address(void* location, MPI_Aint* Address);
```
After structing derived datatype, one also need to commit it for use using `MPI_Type_commit`.

### Other constructors
`MPI_Type_struct` works for most generous case where we need to provide every detailed information. However, in some cases, we may have some special types of data, e.g., arrays, which itself uses contiguous address and same datatype. We can save time by using the following constructors.

#### `MPI_Type_vector`
Consider the case where we want to send some row part of a matrix A

#### `MPI_Type_contiguous`

#### `MPI_Type_indexed` 
